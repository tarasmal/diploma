{
 "cells": [
  {
   "cell_type": "code",
   "id": "714215a9fe40780f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T22:13:38.816585Z",
     "start_time": "2025-05-03T22:13:33.917335Z"
    }
   },
   "source": "%pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\taras\\pycharmprojects\\diploma\\.venv\\lib\\site-packages (2.5.1+cu121)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-win_amd64.whl (6.1 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-win_amd64.whl (4.1 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\taras\\pycharmprojects\\diploma\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\taras\\pycharmprojects\\diploma\\.venv\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\taras\\pycharmprojects\\diploma\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\taras\\pycharmprojects\\diploma\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\taras\\pycharmprojects\\diploma\\.venv\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\taras\\pycharmprojects\\diploma\\.venv\\lib\\site-packages (from torch) (80.0.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\taras\\pycharmprojects\\diploma\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\taras\\pycharmprojects\\diploma\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\taras\\pycharmprojects\\diploma\\.venv\\lib\\site-packages (from torchvision) (2.2.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\taras\\pycharmprojects\\diploma\\.venv\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\taras\\pycharmprojects\\diploma\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "Successfully installed torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T19:19:47.573830Z",
     "start_time": "2025-05-04T19:19:47.393048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random, json, numpy as np, torch, pymongo\n",
    "import torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "SEED = 42\n",
    "BATCH = 512\n",
    "EPOCHS = 15\n",
    "LR = 3e-4\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "import torch, subprocess, sys, os\n",
    "\n",
    "print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
    "print(\"torch.version.cuda:\", torch.version.cuda)\n",
    "print(\"GPU count:\", torch.cuda.device_count())\n"
   ],
   "id": "89d05819",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available(): True\n",
      "torch.version.cuda: 12.1\n",
      "GPU count: 1\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "1bcf3342",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T19:29:11.048449Z",
     "start_time": "2025-05-04T19:29:00.238125Z"
    }
   },
   "source": [
    "client = pymongo.MongoClient('mongodb://localhost:27017')\n",
    "db = client['dota']\n",
    "matches_info = db['matches_info']\n",
    "\n",
    "matches_raw = list(\n",
    "    matches_info.find(\n",
    "        {\n",
    "            'players.9': {'$exists': True},\n",
    "            'picks_bans': {'$exists': True}\n",
    "        },\n",
    "        {\n",
    "            '_id': 0,\n",
    "            'match_id': 1,\n",
    "            'picks_bans': 1\n",
    "        }\n",
    "    )\n",
    ")\n",
    "print(\"Loaded\", len(matches_raw), \"matches with picks_bans\")\n",
    "\n",
    "max_id = max(\n",
    "    h[\"hero_id\"]\n",
    "    for m in matches_raw\n",
    "    for h in m[\"picks_bans\"]\n",
    "    if h.get(\"is_pick\")\n",
    ")\n",
    "HERO_COUNT = max_id + 1\n",
    "print(\"HERO_COUNT =\", HERO_COUNT)\n",
    "print('Loaded', len(matches_raw), 'matches')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 43439 matches with picks_bans\n",
      "HERO_COUNT = 146\n",
      "Loaded 43439 matches\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "d6d2bb5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T19:30:31.688624Z",
     "start_time": "2025-05-04T19:30:31.683428Z"
    }
   },
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def generate_examples_parallel(pb: List[Dict]):\n",
    "    picks = [p for p in pb if p.get('is_pick')]\n",
    "    rad = sorted([p for p in picks if p['team']==0], key=lambda x: x['order'])\n",
    "    dire = sorted([p for p in picks if p['team']==1], key=lambda x: x['order'])\n",
    "    phases = [(2,2),(2,2),(1,1)]\n",
    "    ex, vis, r_i, d_i = [], [], 0, 0\n",
    "    for r_n, d_n in phases:\n",
    "        r_now, d_now = rad[r_i:r_i+r_n], dire[d_i:d_i+d_n]\n",
    "        for i,p in enumerate(r_now):\n",
    "            ex.append({'input_H': vis + [q['hero_id'] for q in r_now[:i]],\n",
    "                       'team':0,'y':p['hero_id']})\n",
    "        for i,p in enumerate(d_now):\n",
    "            ex.append({'input_H': vis + [q['hero_id'] for q in d_now[:i]],\n",
    "                       'team':1,'y':p['hero_id']})\n",
    "        vis += [p['hero_id'] for p in r_now+d_now]\n",
    "        r_i += r_n; d_i += d_n\n",
    "    return ex"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "0ecbcbfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T19:30:32.961382Z",
     "start_time": "2025-05-04T19:30:32.956878Z"
    }
   },
   "source": [
    "class DraftDataset(Dataset):\n",
    "    def __init__(self, matches):\n",
    "        if hasattr(matches, \"to_dict\"):\n",
    "            matches = matches.to_dict(\"records\")\n",
    "        self.samples = []\n",
    "        for m in matches:\n",
    "            if \"picks_bans\" in m:\n",
    "                self.samples += generate_examples_parallel(m[\"picks_bans\"])\n",
    "        random.shuffle(self.samples)\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.samples[idx]\n",
    "        x = np.zeros(2*HERO_COUNT, dtype=np.float32)\n",
    "        for h in s[\"input_H\"]:\n",
    "            x[h] = 1.0\n",
    "        mask = np.zeros(HERO_COUNT, dtype=np.float32)\n",
    "        mask[s[\"input_H\"]] = 1.0\n",
    "        return torch.tensor(x), torch.tensor(mask), torch.tensor(s[\"y\"])\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "031e9a0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T19:30:34.951912Z",
     "start_time": "2025-05-04T19:30:34.947065Z"
    }
   },
   "source": [
    "class DraftNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2 * HERO_COUNT, 512), torch.nn.SiLU(),\n",
    "            torch.nn.Linear(512, 256),            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(256, HERO_COUNT)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        logits = self.net(x)\n",
    "        return logits.masked_fill(mask.bool(), -1e9)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "c2987fc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T22:22:08.881324Z",
     "start_time": "2025-05-03T22:22:08.824870Z"
    }
   },
   "source": [
    "def train_model(matches):\n",
    "    ds = DraftDataset(matches)\n",
    "    train_size = int(0.9*len(ds))\n",
    "    tr_ds, val_ds = random_split(ds, [train_size, len(ds)-train_size],\n",
    "                                 generator=torch.Generator().manual_seed(SEED))\n",
    "    dl_tr = DataLoader(tr_ds, batch_size=BATCH, shuffle=True, pin_memory=True)\n",
    "    dl_val = DataLoader(val_ds, batch_size=BATCH, pin_memory=True)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    net = DraftNet().to(device)\n",
    "    opt = torch.optim.AdamW(net.parameters(), lr=LR)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        net.train()\n",
    "        for x,mask,y in dl_tr:\n",
    "            x,mask,y = x.to(device), mask.to(device), y.to(device)\n",
    "            opt.zero_grad(); loss = loss_fn(net(x,mask), y); loss.backward(); opt.step()\n",
    "\n",
    "        net.eval(); top1=top3=total=0\n",
    "        with torch.no_grad():\n",
    "            for x,mask,y in dl_val:\n",
    "                x,mask,y = x.to(device), mask.to(device), y.to(device)\n",
    "                logits = net(x,mask)\n",
    "                _, idx = logits.topk(3,1)\n",
    "                total += y.size(0)\n",
    "                top1 += (idx[:,0]==y).sum().item()\n",
    "                top3 += ((idx==y.unsqueeze(1)).any(1)).sum().item()\n",
    "        print(f'E{epoch:02d} top1={top1/total:.3f} top3={top3/total:.3f}')\n",
    "\n",
    "    torch.save(net.state_dict(), 'draftnet.pt')\n",
    "    return net\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "707d39df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T22:25:04.062503Z",
     "start_time": "2025-05-03T22:22:14.490419Z"
    }
   },
   "source": [
    "net = train_model(matches_raw)\n",
    "torch.save(net.state_dict(), \"draftnet.pt\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E00 top1=0.065 top3=0.137\n",
      "E01 top1=0.069 top3=0.145\n",
      "E02 top1=0.069 top3=0.147\n",
      "E03 top1=0.070 top3=0.147\n",
      "E04 top1=0.069 top3=0.147\n",
      "E05 top1=0.070 top3=0.146\n",
      "E06 top1=0.070 top3=0.147\n",
      "E07 top1=0.070 top3=0.147\n",
      "E08 top1=0.070 top3=0.148\n",
      "E09 top1=0.070 top3=0.147\n",
      "E10 top1=0.070 top3=0.147\n",
      "E11 top1=0.071 top3=0.147\n",
      "E12 top1=0.070 top3=0.146\n",
      "E13 top1=0.070 top3=0.146\n",
      "E14 top1=0.070 top3=0.146\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T19:59:39.041033Z",
     "start_time": "2025-05-04T19:59:39.033154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "heroes_raw = list(db.heroes.find({}, {'_id': 0, 'id': 1, 'localized_name': 1}))\n",
    "name2id = {h['localized_name']: h['id'] for h in heroes_raw}\n",
    "id2name = {h['id']: h['localized_name'] for h in heroes_raw}\n",
    "\n",
    "radiant_picks = [\n",
    "    name2id['Lina'],\n",
    "    name2id['Sniper'],\n",
    "    name2id['Doom'],\n",
    "    name2id['Oracle'],\n",
    "]\n",
    "dire_picks = [\n",
    "    name2id['Morphling'],\n",
    "    name2id['Zeus'],\n",
    "    name2id['Axe'],\n",
    "    name2id['Abaddon'],\n",
    "]\n",
    "dire_picks"
   ],
   "id": "78eae47607a40f6b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 22, 2, 102]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T19:31:51.634351Z",
     "start_time": "2025-05-04T19:31:51.610589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch, numpy as np, torch.nn.functional as F\n",
    "HERO_COUNT = torch.load('draftnet.pt', weights_only=True)['net.0.weight'].shape[1] // 2\n",
    "\n",
    "class DraftNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2*HERO_COUNT, 512), torch.nn.SiLU(),\n",
    "            torch.nn.Linear(512, 256),          torch.nn.SiLU(),\n",
    "            torch.nn.Linear(256, HERO_COUNT)\n",
    "        )\n",
    "    def forward(self, x, mask):\n",
    "        logits = self.net(x)\n",
    "        return logits.masked_fill(mask.bool(), -1e9)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model  = DraftNet().to(device)\n",
    "model.load_state_dict(torch.load('draftnet.pt', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "def recommend(my_picks, opp_picks, topk=5, T=1.0):\n",
    "    x = np.zeros(2*HERO_COUNT, dtype=np.float32)\n",
    "    for h in my_picks:  x[h] = 1.0\n",
    "    for h in opp_picks: x[h+HERO_COUNT] = 1.0\n",
    "    mask = np.zeros(HERO_COUNT, dtype=np.float32)\n",
    "    mask[my_picks + opp_picks] = 1.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(torch.tensor(x).unsqueeze(0).to(device),\n",
    "                       torch.tensor(mask).unsqueeze(0).to(device)) / T\n",
    "        probs = torch.softmax(logits, dim=1)[0].cpu().numpy()\n",
    "        top = probs.argsort()[-topk:][::-1]\n",
    "        return [(id2name[h], probs[h]) for h in top]\n"
   ],
   "id": "6004f86a00099d17",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taras\\AppData\\Local\\Temp\\ipykernel_31140\\1965879010.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('draftnet.pt', map_location=device))\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T20:02:02.793628Z",
     "start_time": "2025-05-04T20:02:02.788638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "top = recommend(my_picks=dire_picks, opp_picks=radiant_picks, topk=5)\n",
    "#top = recommend(my_picks=radiant_picks, opp_picks=dire_picks, topk=5)\n",
    "\n",
    "for name, prob in top:\n",
    "    print(f\"{name:<15} {prob:.3f}\")\n"
   ],
   "id": "54a3dac5ca0d76e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jakiro          0.035\n",
      "Lion            0.029\n",
      "Ancient Apparition 0.026\n",
      "Queen of Pain   0.025\n",
      "Rubick          0.025\n"
     ]
    }
   ],
   "execution_count": 49
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "id": "08e02763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:17:29.360822Z",
     "start_time": "2025-06-08T21:17:26.781431Z"
    }
   },
   "source": [
    "!pip install --quiet torch pymongo numpy pandas tqdm"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "8daeb3f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T03:37:23.046703Z",
     "start_time": "2025-06-13T03:37:21.458347Z"
    }
   },
   "source": [
    "from pymongo import MongoClient\n",
    "import numpy as np, pandas as pd, torch, torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "heroes_json=list(client.dota.heroes.find({}, {'_id':0}))\n",
    "print('Heroes', len(heroes_json))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heroes 126\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "5944036a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T03:37:53.631308Z",
     "start_time": "2025-06-13T03:37:53.626208Z"
    }
   },
   "source": [
    "PROFILE_COLS=['phase_1_winrate','phase_2_winrate','pro_winrate']\n",
    "ROLE_LIST=['Carry','Mid','Support','Durable','Disabler','Nuker','Pusher','Initiator']\n",
    "ROLE_IDX={r:i for i,r in enumerate(ROLE_LIST)}\n",
    "\n",
    "hero_profile={}\n",
    "role_matrix=np.zeros((max(h['id'] for h in heroes_json)+1, len(ROLE_LIST)),dtype=np.float32)\n",
    "for doc in heroes_json:\n",
    "    hid=doc['id']\n",
    "    base=np.asarray([doc.get(c,0.5) for c in PROFILE_COLS],dtype=np.float32)\n",
    "    role_vec=np.zeros(len(ROLE_LIST),dtype=np.float32)\n",
    "    for r in doc.get('roles',[]): \n",
    "        if r in ROLE_IDX: role_vec[ROLE_IDX[r]]=1.\n",
    "    hero_profile[hid]=np.concatenate([base, role_vec])\n",
    "    role_matrix[hid]=role_vec\n",
    "PROFILE_DIM=len(PROFILE_COLS)+len(ROLE_LIST)\n",
    "HERO_COUNT=len(role_matrix)\n",
    "print('PROFILE_DIM',PROFILE_DIM,'HERO_COUNT',HERO_COUNT)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROFILE_DIM 11 HERO_COUNT 146\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "9a6d991f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T03:38:44.821285Z",
     "start_time": "2025-06-13T03:38:44.817044Z"
    }
   },
   "source": [
    "def agg_profile(ids):\n",
    "    if not ids: return np.zeros(PROFILE_DIM,dtype=np.float32)\n",
    "    return np.mean([hero_profile[i] for i in ids],axis=0)\n",
    "def role_counts(ids):\n",
    "    n_carry   = int(sum(role_matrix[i, ROLE_IDX['Carry']]   for i in ids))\n",
    "    n_support = int(sum(role_matrix[i, ROLE_IDX['Support']] for i in ids))\n",
    "    return n_carry, n_support\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "07564d13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T03:38:54.488834Z",
     "start_time": "2025-06-13T03:38:46.726384Z"
    }
   },
   "source": [
    "def int_idx(lst, offset=0):\n",
    "    if not lst:\n",
    "        return np.array([], dtype=np.int64)\n",
    "    return offset + np.asarray(lst, dtype=np.int64)\n",
    "\n",
    "matches=list(client.dota.matches_info.find({}, {'picks_bans':1}))\n",
    "PHASES=[(2,2),(2,2),(1,1)]\n",
    "examples=[]\n",
    "for m in tqdm(matches):\n",
    "    pb=m.get('picks_bans')\n",
    "    if not pb or sum(1 for p in pb if p.get('is_pick'))!=10: continue\n",
    "    picks=sorted([p for p in pb if p['is_pick']], key=lambda x:x['order'])\n",
    "    rad=[p['hero_id'] for p in picks if p['team']==0]\n",
    "    dire=[p['hero_id'] for p in picks if p['team']==1]\n",
    "    r_idx=d_idx=0\n",
    "    for r_n,d_n in PHASES:\n",
    "        r_now=rad[r_idx:r_idx+r_n]; d_now=dire[d_idx:d_idx+d_n]\n",
    "        for i,h in enumerate(r_now):\n",
    "            my=rad[:r_idx+i]; opp=dire[:d_idx]\n",
    "            c,s=role_counts(my)\n",
    "            x=np.zeros(2*HERO_COUNT+2*PROFILE_DIM+2,dtype=np.float32)\n",
    "            x[int_idx(my)] = 1.\n",
    "            x[int_idx(opp, HERO_COUNT)] = 1.\n",
    "            x[2*HERO_COUNT:2*HERO_COUNT+PROFILE_DIM]=agg_profile(my)\n",
    "            x[2*HERO_COUNT+PROFILE_DIM:2*HERO_COUNT+2*PROFILE_DIM]=agg_profile(opp)\n",
    "            x[-2]=c; x[-1]=s\n",
    "            mask=np.zeros(HERO_COUNT,dtype=bool); mask[int_idx(my + opp)] = True\n",
    "            examples.append((x,mask,h))\n",
    "        for i,h in enumerate(d_now):\n",
    "            my=dire[:d_idx+i]; opp=rad[:r_idx+r_n]\n",
    "            c,s=role_counts(my)\n",
    "            x=np.zeros(2*HERO_COUNT+2*PROFILE_DIM+2,dtype=np.float32)\n",
    "            x[int_idx(opp)] = 1.\n",
    "            x[int_idx(my, HERO_COUNT)] = 1.\n",
    "            x[2*HERO_COUNT:2*HERO_COUNT+PROFILE_DIM]=agg_profile(opp)\n",
    "            x[2*HERO_COUNT+PROFILE_DIM:2*HERO_COUNT+2*PROFILE_DIM]=agg_profile(my)\n",
    "            x[-2]=c; x[-1]=s\n",
    "            mask=np.zeros(HERO_COUNT,dtype=bool); mask[int_idx(my + opp)] = True\n",
    "            examples.append((x,mask,h))\n",
    "        r_idx+=r_n; d_idx+=d_n\n",
    "print('Examples', len(examples))\n",
    "INPUT_DIM=2*HERO_COUNT+2*PROFILE_DIM+2\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44373/44373 [00:06<00:00, 6525.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples 262867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "f871245b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T23:24:35.786584Z",
     "start_time": "2025-05-22T23:24:34.682676Z"
    }
   },
   "source": [
    "class DraftDS(torch.utils.data.Dataset):\n",
    "    def __init__(self,samples):\n",
    "        self.x=[torch.from_numpy(s[0]) for s in samples]\n",
    "        self.m=[torch.from_numpy(s[1]) for s in samples]\n",
    "        self.y=torch.tensor([s[2] for s in samples],dtype=torch.long)\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self,i): return self.x[i],self.m[i],self.y[i]\n",
    "\n",
    "ds=DraftDS(examples)\n",
    "train_size=int(0.9*len(ds)); val_size=len(ds)-train_size\n",
    "train_ds, val_ds = torch.utils.data.random_split(ds,[train_size,val_size],\n",
    "                                                generator=torch.Generator().manual_seed(42))\n",
    "train_dl=torch.utils.data.DataLoader(train_ds,batch_size=1024,shuffle=True,num_workers=0,pin_memory=True)\n",
    "val_dl  =torch.utils.data.DataLoader(val_ds,batch_size=1024,shuffle=False,num_workers=0,pin_memory=True)\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "fd57e578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T03:37:43.029755Z",
     "start_time": "2025-06-13T03:37:43.007193Z"
    }
   },
   "source": [
    "class DraftNet(nn.Module):\n",
    "    def __init__(self,input_dim):\n",
    "        super().__init__()\n",
    "        self.layers=nn.Sequential(\n",
    "            nn.Linear(input_dim,512), nn.SiLU(),\n",
    "            nn.Linear(512,256),       nn.SiLU(),\n",
    "            nn.Linear(256,HERO_COUNT)\n",
    "        )\n",
    "    def forward(self,x,mask):\n",
    "        logits=self.layers(x)\n",
    "        return logits.masked_fill(mask.bool(), -65504.0)\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=DraftNet(INPUT_DIM).to(device)\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'INPUT_DIM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[32m     11\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m logits.masked_fill(mask.bool(), -\u001B[32m65504.0\u001B[39m)\n\u001B[32m     13\u001B[39m device=torch.device(\u001B[33m'\u001B[39m\u001B[33mcuda\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch.cuda.is_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m'\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m model=DraftNet(\u001B[43mINPUT_DIM\u001B[49m).to(device)\n",
      "\u001B[31mNameError\u001B[39m: name 'INPUT_DIM' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "f5c9fb2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T23:27:03.535607Z",
     "start_time": "2025-05-22T23:25:49.590095Z"
    }
   },
   "source": [
    "from tqdm.auto import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "EPOCHS   = 20\n",
    "BATCH_SZ = train_dl.batch_size\n",
    "scaler   = GradScaler()\n",
    "loss_fn  = nn.CrossEntropyLoss()\n",
    "opt      = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def top1(out, target):\n",
    "    return (out.topk(1, -1).indices.squeeze(-1) == target).float().mean().item()\n",
    "\n",
    "for ep in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_bar = tqdm(train_dl, desc=f\"Epoch {ep:02d} [train]\", leave=False)\n",
    "    tl = 0\n",
    "    for x, m, y in train_bar:\n",
    "        x, m, y = x.to(device, non_blocking=True), m.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with autocast():\n",
    "            out  = model(x, m)\n",
    "            loss = loss_fn(out, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        tl += loss.item() * x.size(0)\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    vl = va1 = 0\n",
    "    with torch.no_grad(), autocast():\n",
    "        for x, m, y in tqdm(val_dl, desc=f\"Epoch {ep:02d} [valid]\", leave=False):\n",
    "            x, m, y = x.to(device, non_blocking=True), m.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "            out  = model(x, m)\n",
    "            loss = loss_fn(out, y)\n",
    "\n",
    "            vl  += loss.item() * x.size(0)\n",
    "            va1 += (out.topk(1, -1).indices.squeeze(-1) == y).float().sum().item()\n",
    "\n",
    "    n_train, n_val = len(train_dl.dataset), len(val_dl.dataset)\n",
    "    print(f\"Ep{ep:02d} | train_loss {tl/n_train:.4f} | \"\n",
    "          f\"val_loss {vl/n_val:.4f} | val@1 {va1/n_val:.3f}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taras\\AppData\\Local\\Temp\\ipykernel_9720\\1445708123.py:6: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler   = GradScaler()\n",
      "Epoch 01 [train]:   0%|          | 0/232 [00:00<?, ?it/s]C:\\Users\\taras\\AppData\\Local\\Temp\\ipykernel_9720\\1445708123.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\taras\\AppData\\Local\\Temp\\ipykernel_9720\\1445708123.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), autocast():\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep01 | train_loss 4.3526 | val_loss 4.3526 | val@1 0.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep02 | train_loss 4.3438 | val_loss 4.3459 | val@1 0.059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep03 | train_loss 4.3362 | val_loss 4.3422 | val@1 0.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep04 | train_loss 4.3305 | val_loss 4.3374 | val@1 0.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep05 | train_loss 4.3256 | val_loss 4.3356 | val@1 0.059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep06 | train_loss 4.3220 | val_loss 4.3343 | val@1 0.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep07 | train_loss 4.3186 | val_loss 4.3348 | val@1 0.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep08 | train_loss 4.3158 | val_loss 4.3352 | val@1 0.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep09 | train_loss 4.3131 | val_loss 4.3337 | val@1 0.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep10 | train_loss 4.3107 | val_loss 4.3347 | val@1 0.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep11 | train_loss 4.3085 | val_loss 4.3353 | val@1 0.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep12 | train_loss 4.3060 | val_loss 4.3355 | val@1 0.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep13 | train_loss 4.3041 | val_loss 4.3362 | val@1 0.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep14 | train_loss 4.3019 | val_loss 4.3363 | val@1 0.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep15 | train_loss 4.2994 | val_loss 4.3371 | val@1 0.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep16 | train_loss 4.2975 | val_loss 4.3378 | val@1 0.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep17 | train_loss 4.2953 | val_loss 4.3375 | val@1 0.056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep18 | train_loss 4.2933 | val_loss 4.3382 | val@1 0.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep19 | train_loss 4.2911 | val_loss 4.3410 | val@1 0.056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep20 | train_loss 4.2893 | val_loss 4.3399 | val@1 0.056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "11f72d67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T23:27:11.726977Z",
     "start_time": "2025-05-22T23:27:11.714307Z"
    }
   },
   "source": [
    "torch.save(model.state_dict(), '../draftnet_roles_only.pt')\n",
    "import json\n",
    "with open('../hero_profile_roles.json', 'w') as f:\n",
    "    json.dump({str(k):v.tolist() for k,v in hero_profile.items()},f,indent=2)\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T03:37:34.457847Z",
     "start_time": "2025-06-13T03:37:34.449751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "heroes_raw = list(client.dota.heroes.find({}, {'_id': 0, 'id': 1, 'localized_name': 1}))\n",
    "name2id = {h['localized_name']: h['id'] for h in heroes_raw}\n",
    "id2name = {h['id']: h['localized_name'] for h in heroes_raw}\n",
    "\n",
    "radiant_picks = [\n",
    "    name2id[\"Terrorblade\"],\n",
    "    name2id[\"Ember Spirit\"],\n",
    "    name2id[\"Magnus\"],\n",
    "    name2id[\"Oracle\"],\n",
    "]\n",
    "dire_picks = [\n",
    "    name2id[\"Morphling\"],\n",
    "    name2id[\"Puck\"],\n",
    "    name2id[\"Beastmaster\"],\n",
    "    name2id[\"Snapfire\"],\n",
    "]\n"
   ],
   "id": "f71779c83d05381d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T03:39:11.982015Z",
     "start_time": "2025-06-13T03:39:11.801308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_PATH = \"../draftnet_roles_only.pt\"\n",
    "\n",
    "def load_model():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    mdl = DraftNet(INPUT_DIM).to(device)\n",
    "    state = torch.load(MODEL_PATH, map_location=\"cpu\")\n",
    "    mdl.load_state_dict(state)\n",
    "    mdl.eval()\n",
    "    print(f\"[LOADED] DraftNet | input_dim={INPUT_DIM}, heroes={HERO_COUNT}\")\n",
    "    return mdl\n",
    "\n",
    "model = load_model()"
   ],
   "id": "daa53fe6b72b1f6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOADED] DraftNet | input_dim=316, heroes=146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taras\\AppData\\Local\\Temp\\ipykernel_29528\\2584792098.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(MODEL_PATH, map_location=\"cpu\")\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T03:39:17.767980Z",
     "start_time": "2025-06-13T03:39:17.760922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def role_counts(picks):\n",
    "    if not picks:\n",
    "        return 0, 0\n",
    "    carr = int(sum(role_matrix[h, ROLE_IDX['Carry']]   for h in picks))\n",
    "    supp = int(sum(role_matrix[h, ROLE_IDX['Support']] for h in picks))\n",
    "    return carr, supp\n",
    "\n",
    "def build_x(my, opp):\n",
    "    n_carry, n_support = role_counts(my)\n",
    "    x = np.zeros(2 * HERO_COUNT + 2 * PROFILE_DIM + 2, dtype=np.float32)\n",
    "\n",
    "    if my:\n",
    "        x[np.asarray(my, dtype=np.int64)] = 1.\n",
    "    if opp:\n",
    "        x[HERO_COUNT + np.asarray(opp, dtype=np.int64)] = 1.\n",
    "\n",
    "    x[2*HERO_COUNT : 2*HERO_COUNT + PROFILE_DIM]               = agg_profile(my)\n",
    "    x[2*HERO_COUNT + PROFILE_DIM : 2*HERO_COUNT + 2*PROFILE_DIM] = agg_profile(opp)\n",
    "\n",
    "    x[-2] = n_carry\n",
    "    x[-1] = n_support\n",
    "    return x\n",
    "\n",
    "def recommend(my_picks, opp_picks, topk=5):\n",
    "    x_np   = build_x(my_picks, opp_picks)\n",
    "    mask_np = np.zeros(HERO_COUNT, dtype=bool)\n",
    "    mask_np[my_picks + opp_picks] = True\n",
    "\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        x    = torch.from_numpy(x_np).unsqueeze(0).to(device)\n",
    "        mask = torch.from_numpy(mask_np).unsqueeze(0).to(device)\n",
    "        logits = model(x, mask)\n",
    "        probs  = torch.softmax(logits, dim=1)[0].cpu().numpy()\n",
    "\n",
    "    top_ids = probs.argsort()[-topk:][::-1]\n",
    "    return [(id2name[i], float(probs[i])) for i in top_ids]\n",
    "\n"
   ],
   "id": "54ebab3ade43d5fd",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T03:39:20.966854Z",
     "start_time": "2025-06-13T03:39:20.621269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "top = recommend(my_picks=radiant_picks, opp_picks=dire_picks, topk=5)\n",
    "for name, prob in top:\n",
    "    print(f\"{name:<15} {prob:.3f}\")"
   ],
   "id": "21bcce52294a9c0a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taras\\AppData\\Local\\Temp\\ipykernel_29528\\3537327588.py:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthshaker     0.042\n",
      "Leshrac         0.031\n",
      "Axe             0.028\n",
      "Huskar          0.026\n",
      "Tiny            0.026\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
